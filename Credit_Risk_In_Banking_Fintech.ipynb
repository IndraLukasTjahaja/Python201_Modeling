{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Credit_Risk_In_Banking_Fintech",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IndraLukasTjahaja/Python201_Modeling/blob/master/Credit_Risk_In_Banking_Fintech.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7TWDWzEkUKY"
      },
      "source": [
        "# 0. Persiapan Google Colaboratory dan Downloading dataset\n",
        "\n",
        "Karena data tersedia di website tjahaja, maka kita dapat langsung run dari Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7r5AKySplVhI"
      },
      "source": [
        "# Bab III: Metodologi Data Science CRISP-DM dengan Score Card "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-U2Nfsln8JU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "outputId": "3a756bd2-5484-4820-a14a-bc159acc0fa1"
      },
      "source": [
        "## III.2.1 Persiapan data dan impor ke Python\n",
        "\n",
        "# library panda untuk menggunakan data frame\n",
        "import pandas as pd\n",
        "\n",
        "# Pengaturan folder tempat data / Google Colab\n",
        "\n",
        "# Impor data dari excel xls ke Python\n",
        "df = pd.read_excel('https://github.com/IndraLukasTjahaja/Digital_Credit_Risk/blob/main/Dataset/Credit_Scoring_Dataset.xlsx')\n",
        "print(\"read datafile\")\n",
        "# Alternative \n",
        "# Untuk grup 1: https://github.com/IndraLukasTjahaja/Python201_Modeling/blob/master/Dataset/german_credit_easy.xlsx\n",
        "# Untuk grup 2: https://github.com/IndraLukasTjahaja/Python201_Modeling/blob/master/Dataset/OnClass_CreditScoring_data_v2.xlsx  \n",
        "# Untuk grup 3: https://github.com/IndraLukasTjahaja/Python201_Modeling/blob/master/Dataset/simulation_credit_kaggle_laotse.xlsx \n",
        "# Untuk yang mencari tantangan: https://github.com/IndraLukasTjahaja/Python201_Modeling/blob/master/Dataset/Fraud_Scoring_Dataset.xlsx"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "XLRDError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mXLRDError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-8743b50764b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Impor data dari excel xls ke Python\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://github.com/IndraLukasTjahaja/Digital_Credit_Risk/blob/main/Dataset/Credit_Scoring_Dataset.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"read datafile\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Alternative\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m                 )\n\u001b[1;32m    295\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine)\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstringify_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__fspath__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/excel/_xlrd.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0merr_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Install xlrd >= 1.0.0 for Excel support\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mimport_optional_dependency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"xlrd\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m    349\u001b[0m             \u001b[0;31m# N.B. xlrd.Book has a read attribute too\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/excel/_xlrd.py\u001b[0m in \u001b[0;36mload_workbook\u001b[0;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xlrd/__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[0;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mformatting_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformatting_info\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0mon_demand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_demand\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0mragged_rows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mragged_rows\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         )\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xlrd/book.py\u001b[0m in \u001b[0;36mopen_workbook_xls\u001b[0;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mbk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_time_stage_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mbiff_version\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXL_WORKBOOK_GLOBALS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbiff_version\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mXLRDError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can't determine file's BIFF version\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xlrd/book.py\u001b[0m in \u001b[0;36mgetbof\u001b[0;34m(self, rqd_stream)\u001b[0m\n\u001b[1;32m   1269\u001b[0m             \u001b[0mbof_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Expected BOF record; met end of file'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1270\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mopcode\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbofcodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1271\u001b[0;31m             \u001b[0mbof_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Expected BOF record; found %r'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msavpos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0msavpos\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1272\u001b[0m         \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget2bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1273\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlength\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mMY_EOF\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xlrd/book.py\u001b[0m in \u001b[0;36mbof_error\u001b[0;34m(msg)\u001b[0m\n\u001b[1;32m   1263\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mDEBUG\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"reqd: 0x%04x\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mrqd_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1264\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mbof_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1265\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mXLRDError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unsupported format, or corrupt file: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1266\u001b[0m         \u001b[0msavpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_position\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m         \u001b[0mopcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget2bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mXLRDError\u001b[0m: Unsupported format, or corrupt file: Expected BOF record; found b'\\n\\n\\n\\n\\n\\n<!'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCfzvDo7oei5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "bc765897-b3b2-42d5-bc27-5bb0a4d39add"
      },
      "source": [
        "# Membaca file dan menera[kan tipe variabel\n",
        "# Koding ini harus diganti, menyesuaikan dengan tipe data yang digunakan\n",
        "df.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-fc67b62fd63f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Koding ini harus diganti, menyesuaikan dengan tipe data yang digunakan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'installment_as_income_perc'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstallment_as_income_perc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'category'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'present_res_since'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpresent_res_since\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'category'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'people_under_maintenance'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpeople_under_maintenance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'category'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5139\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5140\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5141\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5143\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'installment_as_income_perc'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6WNLj4GpZfG"
      },
      "source": [
        "## III.2.2 Penjelasan untuk setiap variabel di dataset\n",
        "\n",
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5awqjixkELAB"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjNZ7zEP9DeL"
      },
      "source": [
        "## III.2.4 Eksplorasi data untuk memeriksa hasil hipotesis\n",
        "\n",
        "# Untuk melihat frekuensi dari variabel default\n",
        "\n",
        "print(df['default'].value_counts())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_C6qAFZsfNB"
      },
      "source": [
        "# Untuk melihat frekuensi dari variabel credit_history\n",
        "print(df['credit_history'].value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvrXkg16tROz"
      },
      "source": [
        "# Untuk melihat proporsi dari variabel credit_history\n",
        "print(df['credit_history'].value_counts(normalize=True) * 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Z9V72FCtZL1"
      },
      "source": [
        "# Untuk melihat proporsi dari variabel credit_history\n",
        "# atau\n",
        "print(df['credit_history'].value_counts() / len(df['credit_history']) * 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwXicMILu-Wj"
      },
      "source": [
        "# Melihat kaitan antara variabel credit_history dengan default (gagal bayar)\n",
        "print(pd.crosstab(df['credit_history'], df['default']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9lerdZUw9Xm"
      },
      "source": [
        "# Melihat proporsi kaitan antara variabel credit_history dengan default (gagal bayar)\n",
        "print(pd.crosstab(df['credit_history'], df['default'], normalize='index') * 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIv4dHqCBljG"
      },
      "source": [
        "# Rangkuman statistik untuk variabel numerik\n",
        "print(df['age'].describe())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUyGl-o5DICD"
      },
      "source": [
        "# Rangkuman statistik untuk variabel numerik Age, berdasarkan default (gagal bayar atau tidak)\n",
        "df.groupby('default')['age'].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fk95x9QzNC5c"
      },
      "source": [
        "# Menghitung korelasi antara variabel Age dengan default\n",
        "print(df['default'].corr(df['age']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSRLIm9lOsUX"
      },
      "source": [
        "# Uji coba hipotesis apakah ada perbedaan nilai rata-rata variabel Age dengan default (gagal bayar dan tidak gagal bayar)\n",
        "from scipy import stats\n",
        "stats.ttest_ind( df[df.default == 0].age,\n",
        "                 df[df.default == 1].age, nan_policy='omit')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4Ta0PnxxUFT"
      },
      "source": [
        "## III.2.5.1 Distribusi data untuk variabel tipe karakter\n",
        "\n",
        "# Fungsi value_counts().plot(kind='bar')\n",
        "df['credit_history'].value_counts().plot(kind='bar') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1WPAxZe1Qpo"
      },
      "source": [
        "# Karena nama dari isi variabel credit_history panjang, mari kita tampilkan bar secara horizontal\n",
        "df['credit_history'].value_counts().plot(kind='barh') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sULgMOlw1SmL"
      },
      "source": [
        "\n",
        "# atau\n",
        "# Dengan menggunakan fungsi yang sama, menampilkan proporsi\n",
        "# df['credit_history'].value_counts(normalize=True).plot(kind='bar') \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-RWcRqhxzie"
      },
      "source": [
        "# Nilai variabel credit_history dan proporsi default secara plot bar\n",
        "pd.crosstab(df['credit_history'], df['default']).plot(kind='barh', stacked=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptT0qklQByva"
      },
      "source": [
        "# Nilai variabel credit_history dan proporsi default secara plot bar, secara proporsi\n",
        "pd.crosstab(df['credit_history'], df['default'], normalize='index').plot(kind='barh', stacked=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmbnTDudCyyT"
      },
      "source": [
        "## III.2.5.2 Distribusi data untuk variabel tipe numerik\n",
        "\n",
        "# Fungsi distplot() dari library seaborn\n",
        "# Perhatikan bahwa distribusi plot harus tidak memiliki data kosong / missing value.\n",
        "# Oleh karena itu harus menambahkan fungsi dropna() untuk secara sementara tidak\n",
        "# mengikutsertakan missing value dalam pembuatan plot distribusi \n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,10))\n",
        "sns.distplot(df['age'].dropna(), ax=ax).set_title('Distribution Plot') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hp3CIX6vsNP"
      },
      "source": [
        "df.boxplot(column=['age'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CG4Ibrkv5oo"
      },
      "source": [
        "# Menambahkan by di fungsi boxplot\n",
        "df.boxplot(by='default',column=['age'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOAIrQzi6fM8"
      },
      "source": [
        "## III.2.6 Korelasi Antar Variabel\n",
        "\n",
        "import seaborn as sns\n",
        "corr = df.corr()\n",
        "sns.heatmap(corr, xticklabels=corr.columns.values, yticklabels=corr.columns.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5RAfmkj-Jz8"
      },
      "source": [
        "## III.3.1 Penanganan untuk data yang hilang (missing values)\n",
        "\n",
        "# Membuat kopi dari df dan menyimpan sebagai df_prepare\n",
        "df_prepare = df.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hL7PIdF4s0P"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmpNcJL9fpPW"
      },
      "source": [
        "df_prepare.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkJUt0w39gDq"
      },
      "source": [
        "# Koding berikut menggantikan missing value dari semua variabel dengan\n",
        "# nilai yang paling sering muncul (modus)\n",
        "\n",
        "for column in df_prepare.columns:\n",
        "        df_prepare[column].fillna(df_prepare[column].mode()[0], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWRVuIetbndR"
      },
      "source": [
        "## III.3.3 Pembuatan variabel yang baru (Feature Engineering) \n",
        "\n",
        "df_prepare['cicilan_per_bulan'] = df_prepare['credit_amount'] / df_prepare['duration_in_month']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjDzb-gecjkG"
      },
      "source": [
        "# Fungsi boxplot dari variabel cicilan_per_bulan, dengan kemungkinan gagal bayar\n",
        "df_prepare.boxplot(by='default',column=['cicilan_per_bulan'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2yscgZfFEIq"
      },
      "source": [
        "# Menghitung korelasi dan uji coba hipotesis antara variabel cicilan_per_bulan dengan default\n",
        "\n",
        "print(df_prepare['default'].corr(df_prepare['cicilan_per_bulan']))\n",
        "\n",
        "stats.ttest_ind( df_prepare[df_prepare.default == 0].cicilan_per_bulan,\n",
        "                 df_prepare[df_prepare.default == 1].cicilan_per_bulan, nan_policy='omit')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_285qg7Yc_jV"
      },
      "source": [
        "## III.3.4 Transformasi variabel kategori menjadi numerik (One-Hot Encoding) \n",
        "\n",
        "# Koding untuk one hot encoding untuk semua variabel kategori\n",
        "\n",
        "# Langkah pertama adalah membuang variabel ID karena ini adalah identifikasi nasabah\n",
        "df_prepare.drop(['ID'], axis = 1, inplace = True)\n",
        "\n",
        "# Memisahkan variabel kategori dengan variabel numerik\n",
        "dataset_dummies = df_prepare.select_dtypes(exclude = ['float64','int64','int'])\n",
        "dataset_int = df_prepare.select_dtypes(include=['float64','int64','int'])\n",
        "\n",
        "# Memisahkan target/dependent variabel dari dataset dengan variabel kategori\n",
        "target = df_prepare['default']\n",
        "dataset_int.drop(['default'], axis = 1, inplace = True)\n",
        "\n",
        "# Menggunakan function get_dummies dari panda untuk melakukan one hot encoding\n",
        "dataset_dummies_df = pd.get_dummies(dataset_dummies,drop_first = True)\n",
        "    \n",
        "# Menggabungkan dataset variabel kategori dari one hot encoding dengan variabel numerik\n",
        "dataset = pd.concat([dataset_dummies_df, dataset_int], axis = 1)\n",
        "feature_name = dataset.columns\n",
        "df_encoded = pd.concat([dataset, target], axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCGSSJYPd1r4"
      },
      "source": [
        "df_encoded.info()\n",
        "df_encoded.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ekuJPVJ8SqL"
      },
      "source": [
        "# Menentukan variabel dependent (default) dan independent (input untuk model)\n",
        "\n",
        "# X sebagai semua variabel independent, input untuk model\n",
        "X = df_encoded.iloc[:,0:len(df_encoded.columns)-1]\n",
        "\n",
        "# y sebagai target atau variabel dependent\n",
        "y = df_encoded.iloc[:,len(df_encoded.columns)-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdvbcR4zD5KP"
      },
      "source": [
        "X.head()\n",
        "y.head()\n",
        "print(y.value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uoOo9NCExyK"
      },
      "source": [
        "# menggunakan function SMOTE untuk melakukan kombinasi oversampling/undersampling\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# function SMOTE dengan menerapkan proporsi 50%, maka ratio harus menjadi 1.0 Karena ratio mengacu pada proporsi gagal bayar\n",
        "sm = SMOTE(random_state = 42, ratio = 1.0)\n",
        "\n",
        "# Hasil dari function SMOTE disimpan dalam variabel X dan y\n",
        "X_imbal,y_imbal = sm.fit_sample(X,y.ravel())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHG-72KKFBuY"
      },
      "source": [
        "# Melihat jumlah bayar dan gagal bayar nasabah di y_imbal hasil dari SMOTE\n",
        "import collections, numpy\n",
        "collections.Counter(y_imbal)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpSwT3woct0p"
      },
      "source": [
        "# Menggunakan library dan fungsi train_test_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Membagi data set menjadi train dan test, dimana proporsi test adalah 0.3 / 30% dari total data set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =0.3, random_state=42)\n",
        "\n",
        "# Membagi lagi test data set menjadi dua, dimana 15% adalah test dan 15% digunakan sebagai validasi\n",
        "X_test, X_test_holdup, y_test, y_test_holdup = train_test_split(X_test, y_test, test_size =0.5, random_state=42)\n",
        "\n",
        "# Karena X_train dalam bentuk array, tidak akan tersimpan nama variabel independen. Oleh karena itu kita akan simpan dalam bentuk list nama-nama kolom\n",
        "# Akan banyak nama kolomnya\n",
        "kolom_short = [\"act_0DM\",\"act_200DM/salary\",\"act_none\",\"cre_his_critical/other_existing\",\"cre_his_delay\",\"cre_his_paid\",\"cre_his_none/paid\",\"purpose_business\",\"purpose_car(new)\",\"purpose_car(used)\"    ,\"purpose_appli\",\"purpose_education\",\"purpose_furniture\",\"purpose_radio/television\",\"purpose_repairs\",\"purpose_retraining\",\"sav_100DM\",\"sav100_500DM\",\"sav500_1000DM\",\"sav_unknown\",\"emp_1year\"    ,\"emp_1_4years\",\"emp_4_7years\",\"emp_unemployed\",\"inst_2\",\"inst_3\",\"inst_4\",\"male:divorced\",\"male:married\",\"male:single\",\"debtors_guarantor\",\"debtors_none\",\"res_2\",\"res_3\",\"res_4\"  ,\"prop_other\",\"prop_realestate\",\"proy_unknown\",\"other_ins_none\",\"other_inst_stores\",\"hous_own\",\"hous_rent\",\"credits_2\",\"credits_3\",\"credits_4\",\"job_employee\",\"job_unemployed\",\"job_unskilled\"   ,\"people_2\",\"phone_yes\",\"foreign_yes\",\"duration_in_month\",\"credit_amount\",\"age\",\"cicilan_per_bulan\"]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUzroVoBBt31"
      },
      "source": [
        "# Menggunakan scaling dengan standard scaler dari library sklearn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Memanggil fungsi standard scaler\n",
        "sc = StandardScaler()\n",
        "\n",
        "# Merubah nilai X dari Train dan Test menjadi standardisation\n",
        "X_train_scale = sc.fit_transform(X_train)\n",
        "X_test_scale = sc.fit_transform(X_test)\n",
        "X_test_holdup_scale = sc.fit_transform(X_test_holdup)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQw9WDvdCLIH"
      },
      "source": [
        "print(X_train_scale)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6Y1RTLK-6oJ"
      },
      "source": [
        "## III.4. Modeling Decision Tree\n",
        "\n",
        "# Menggunakan fungsi DecisionTree dari library sklearn\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Fungsi Decision Tree, menggunakan opsi dasar saja\n",
        "classifier = DecisionTreeClassifier()\n",
        "\n",
        "# Melakukan model Decision Tree kepada data training\n",
        "# Karena Decision Tree tidak memerlukan scaling, kita akan buat\n",
        "# train dan test tanpa scaling\n",
        "classifier.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EGHLCV_m3eH"
      },
      "source": [
        "\n",
        "import pydotplus\n",
        "import graphviz\n",
        "\n",
        "from sklearn.tree import export_graphviz\n",
        "from sklearn import tree\n",
        "from IPython.display import SVG\n",
        "from graphviz import Source\n",
        "from IPython.display import display, Image\n",
        "from sklearn.externals.six import StringIO\n",
        "\n",
        "# Untuk dapat menggunakan graphviz memerlukan instalasi library yang tepat, silahkan refer ke website berikut untuk petunjuk instalasi:\n",
        "# https://stackoverflow.com/questions/27666846/pydot-invocationexception-graphvizs-executables-not-found\n",
        "\n",
        "dot_data = StringIO()\n",
        "export_graphviz(classifier, out_file=dot_data,  \n",
        "                filled=True, rounded=True,\n",
        "                special_characters=True)\n",
        "\n",
        "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
        "Image(graph.create_png())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aGQkUytnCbw"
      },
      "source": [
        "\n",
        "# Fungsi Decision Tree, menggunakan opsi max_depth\n",
        "classifier = DecisionTreeClassifier(max_depth=3)\n",
        "\n",
        "# Melakukan model Decision Tree kepada data training\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "dot_data = StringIO()\n",
        "export_graphviz(classifier, out_file=dot_data, filled=True,rounded=True,\n",
        "                special_characters=True, feature_names = kolom_short)\n",
        "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
        "graph.write_png('decision_tree_2.png')\n",
        "Image(graph.create_png())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G95vuu8AnWcb"
      },
      "source": [
        "## III.5.1 Implementasi model dari data Train ke data Test \n",
        "\n",
        "\n",
        "# Memprediksi data test dengan menggunakan model Decision Tree\n",
        "predicted = classifier.predict(X_test)\n",
        "predicted_proba = classifier.predict_proba(X_test)\n",
        "\n",
        "# Melihat hasil dari predict ke data test\n",
        "print(predicted)\n",
        "\n",
        "# Melihat hasil dari predict probabilitas ke data test\n",
        "print(predicted_proba)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLgVrdvtngUa"
      },
      "source": [
        "## III.5.2 Evaluasi dengan Confusion Matrix \n",
        "\n",
        "# Menggunakan fungsi Confusion Matrix dari sklearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Kita akan cek hasil confusion matrix antara hasil sebenarnya dengan prediksi dari model ke data test\n",
        "matrix = confusion_matrix(y_test, predicted)\n",
        "\n",
        "# cek hasil matrix\n",
        "print(matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPG-seoxnoNb"
      },
      "source": [
        "## III.5.3 Classification Report\n",
        "\n",
        "# Menggunakan fungsi Classification Report dari sklearn\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Kita akan cek hasil confusion matrix antara hasil sebenarnya dengan prediksi dari model ke data test\n",
        "report = classification_report(y_test, predicted)\n",
        "\n",
        "# cek hasil matrix\n",
        "print(report)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xs0P-S03cFQ"
      },
      "source": [
        "# install scikitplot\n",
        "\n",
        "!pip install -q scikit-plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLHzO0m-23Pk"
      },
      "source": [
        "## III.5.4 Gain and Lift chart \n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# Harap install library scikit-plot terlebih dahulu\n",
        "import scikitplot as skplt\n",
        "\n",
        "# Gain chart\n",
        "skplt.metrics.plot_cumulative_gain(y_test, predicted_proba)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CD9jnnya5Vv0"
      },
      "source": [
        "# Lift chart\n",
        "skplt.metrics.plot_lift_curve(y_test, predicted_proba)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUddlBAbJiAz"
      },
      "source": [
        "# K-S chart\n",
        "skplt.metrics.plot_ks_statistic(y_test, predicted_proba)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xXPZomlfBmX"
      },
      "source": [
        "# Membuat chart ROC dan menghitung AUC\n",
        "skplt.metrics.plot_roc(y_test, predicted_proba)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgsZKqAY1ruz"
      },
      "source": [
        "# Metode dengan Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAdaffZk1zNb"
      },
      "source": [
        "# Model Logistic Regression\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Pembuatan model logistic regression\n",
        "log_reg = LogisticRegression()\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "# Hasil dari model: parameter koefisien\n",
        "parameters = log_reg.coef_\n",
        "print(parameters)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CfAqwzBLBdop"
      },
      "source": [
        "# Metode dengan Logistic Regression dengan Stats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T17JzrrJBiDb"
      },
      "source": [
        "import numpy as np\n",
        "import statsmodels.api as sm\n",
        "\n",
        "model = sm.Logit(y_train, X_train)\n",
        "result = model.fit(method='newton')\n",
        "\n",
        "result.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--OOtypI4o99"
      },
      "source": [
        "# Metode dengan Library Scorecardpy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBQJ_EcQ4toY"
      },
      "source": [
        "# install scorecardpy\n",
        "\n",
        "!pip install -q scorecardpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFvbtOBQ6Mbm"
      },
      "source": [
        "# Credit Scoring using logistic regression with library scorecardpy\n",
        "import scorecardpy as scpy\n",
        "\n",
        "# scorecardpy library sudah memiliki fungsi untuk data split, scale, dan lainnya, oleh karena itu kita akan load df_prepare saja\n",
        "dat = df_prepare"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeMbbMB2-DvR"
      },
      "source": [
        "dat.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDcjV5TT8ozJ"
      },
      "source": [
        "# Filter variabel secara otomatis\n",
        "# Filter otomatis variabel dari fungsi scorecard, dengan tidak mengikutsertakan variabel yang terlalu banyak missing value dan nilai minimum Information Value\n",
        "dt_s = scpy.var_filter(dat, y = 'default')\n",
        "dt_s.drop(['installment_as_income_perc'], axis = 1, inplace = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Kug5vr_97cm"
      },
      "source": [
        "dt_s.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrgxZ3IA87hK"
      },
      "source": [
        "# breaking dt_s menjadi training dan test dataset\n",
        "train, test = scpy.split_df(dt_s, y='default').values()\n",
        "\n",
        "# Melakukan WOE binning\n",
        "bins = scpy.woebin(dt_s, y = 'default')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WV6deI2-s9y"
      },
      "source": [
        "# Melihat plot hasil dari WoE dan IV\n",
        "scpy.woebin_plot(bins)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-ecEh64-y_M"
      },
      "source": [
        "# Hasil dari WoE dan IV secara kalkulasi\n",
        "print(bins)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlYS-nnA_CLT"
      },
      "source": [
        "# Membuat model scorecard\n",
        "\n",
        "# converting train and test into woe values\n",
        "train_woe = scpy.woebin_ply(train, bins)\n",
        "test_woe = scpy.woebin_ply(test, bins)\n",
        "\n",
        "y_train = train_woe.loc[:,'default']\n",
        "X_train = train_woe.loc[:,train_woe.columns != 'default']\n",
        "y_test = test_woe.loc[:,'default']\n",
        "X_test = test_woe.loc[:,train_woe.columns != 'default']\n",
        "\n",
        "# Membuat scorecard dengan menggunakan algoritma logistic regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "lr = LogisticRegression(penalty='l1', C=0.9, solver='saga', n_jobs=-1)\n",
        "lr.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U37sW5GytWBm"
      },
      "source": [
        "# predicted probability\n",
        "# predicted proability\n",
        "train_pred = lr.predict_proba(X_train)[:,1]\n",
        "test_pred = lr.predict_proba(X_test)[:,1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJV5umEfEzNh"
      },
      "source": [
        "# performance ks & roc ------\n",
        "train_perf = scpy.perf_eva(y_train, train_pred, title = \"train\")\n",
        "test_perf = scpy.perf_eva(y_test, test_pred, title = \"test\")\n",
        "\n",
        "# score ------\n",
        "card = scpy.scorecard(bins, lr, X_train.columns)\n",
        "# credit score\n",
        "train_score = scpy.scorecard_ply(train, card, print_step=0)\n",
        "test_score = scpy.scorecard_ply(test, card, print_step=0)\n",
        "\n",
        "# psi\n",
        "scpy.perf_psi(\n",
        "  score = {'train':train_score, 'test':test_score},\n",
        "  label = {'train':y_train, 'test':y_test}\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}